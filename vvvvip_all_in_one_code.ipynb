{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Audio and return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text():\n",
    "    import io\n",
    "    import wave\n",
    "    import pyaudio\n",
    "    import string\n",
    "    import whisper\n",
    "\n",
    "    # Set up audio recording parameters\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1     \n",
    "    RATE = 16000\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 5\n",
    "\n",
    "    # Create an instance of PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open a new stream for recording\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    # Create a buffer to store the recorded audio\n",
    "    frames = []\n",
    "\n",
    "    # Record the audio for the specified number of seconds\n",
    "    print(\"Recording started...\")\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio as a WAV file\n",
    "    with wave.open(\"recorded_audio.wav\", \"wb\") as wav_file:\n",
    "        wav_file.setnchannels(CHANNELS)\n",
    "        wav_file.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wav_file.setframerate(RATE)\n",
    "        wav_file.writeframes(b\"\".join(frames))\n",
    "\n",
    "    ##Model code has been already run above\n",
    "\n",
    "    result = model.transcribe('recorded_audio.wav')\n",
    "\n",
    "    cleaned_result = result['text'].lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "    return cleaned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'open crow'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To be run whenever want to record\n",
    "ressssult = speech_to_text()\n",
    "ressssult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: open crow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import speech_recognition as sr\n",
    "import string\n",
    "import os\n",
    "from email.message import EmailMessage\n",
    "import ssl\n",
    "import smtplib\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recognize_command():\n",
    "   \n",
    "    # with sr.Microphone() as source:\n",
    "    #     print(\"Speak now...\")\n",
    "    #     r.adjust_for_ambient_noise(source)\n",
    "    #     audio = r.listen(source)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # command = r.recognize_google(audio)\n",
    "        # command = command.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "        command = ressssult\n",
    "        print(\"You said: \" + command)\n",
    "       \n",
    "        if \"open\" in command:\n",
    "           \n",
    "\n",
    "\n",
    "            app = command.split(' ')[-1]\n",
    "            os.system(f'start { app}')\n",
    "           \n",
    "       \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I didn't understand that.\")\n",
    "       \n",
    "\n",
    "\n",
    "recognize_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2817036313.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    =[\\\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import speech_recognition as sr\n",
    "# import os\n",
    "\n",
    "# def speech_to_text():\n",
    "#     r = sr.Recognizer()\n",
    "#     with sr.Microphone() as source:\n",
    "#         audio = r.listen(source, phrase_time_limit=5)\n",
    "#         try:\n",
    "#             text = r.recognize_google(audio) V5654VB5WK6789NHYU78ILG9Y;0I'-\n",
    "=[\\\n",
    "#             print(f\"You said: {text}\")\n",
    "#             return text\n",
    "#         except sr.UnknownValueError:\n",
    "#             print(\"Could not understand audio\")\n",
    "#             return None\n",
    "#         except sr.RequestError as e:\n",
    "#             print(f\"Could not request results; {e}\")\n",
    "#             return None\n",
    "\n",
    "# def parse_command(text):\n",
    "#     if \"open\" in text:\n",
    "#         command = text.split(\"open\")[1].strip()\n",
    "#         return command\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# while True:\n",
    "#     text = speech_to_text()\n",
    "#     if 'okay' in text : \n",
    "#         if 'stop' not in text:\n",
    "#             print(text)\n",
    "#     # if text is not None:\n",
    "#     #     command = parse_command(text)\n",
    "#     #     if command is not None:\n",
    "#     #         os.system(f\"open {command}\")  # or any other command you want to execute\n",
    "#     # else:\n",
    "#     #     print(\"No audio input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts speech to text\n",
    "You start giving commands after running the code, as soon as you pause, the command inputting stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechToText_Google():\n",
    "    import speech_recognition as sr\n",
    "    import string\n",
    "\n",
    "    # Initialize the speech recognition engine\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    # Use the microphone as source\n",
    "    with sr.Microphone() as source:\n",
    "        # Set the minimum energy threshold for speech detection\n",
    "        r.energy_threshold = 300\n",
    "        print(\"Speak something...\")\n",
    "        audio = r.listen(source, timeout=1.3,phrase_time_limit=10)\n",
    "\n",
    "    # Use Google speech recognition to convert speech to text\n",
    "    try:\n",
    "        command = r.recognize_google(audio)\n",
    "        cleaned_command = command.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "        # print(\"You said: \" + command)\n",
    "        \n",
    "    except sr.UnknownValueError:\n",
    "        # print(\"Sorry, I could not understand your command.\")\n",
    "        command = 'Sorry, I could not understand your command'\n",
    "\n",
    "    return cleaned_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = speechToText_Google()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sentence = result\n",
    "\n",
    "match = re.search(r'open\\s+\\w+', sentence)\n",
    "\n",
    "if match:\n",
    "    command = match.group()\n",
    "    print(command)\n",
    "else:\n",
    "    print(\"Command not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: invalid locator\n  (Session info: chrome=111.0.5563.111)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00AADCE3]\n\t(No symbol) [0x00A439D1]\n\t(No symbol) [0x00954DA8]\n\t(No symbol) [0x00980292]\n\t(No symbol) [0x009803AB]\n\t(No symbol) [0x009AEE62]\n\t(No symbol) [0x0099AF14]\n\t(No symbol) [0x009AD57C]\n\t(No symbol) [0x0099ACC6]\n\t(No symbol) [0x00976F68]\n\t(No symbol) [0x009780CD]\n\tGetHandleVerifier [0x00D23832+2506274]\n\tGetHandleVerifier [0x00D59794+2727300]\n\tGetHandleVerifier [0x00D5E36C+2746716]\n\tGetHandleVerifier [0x00B56690+617600]\n\t(No symbol) [0x00A4C712]\n\t(No symbol) [0x00A51FF8]\n\t(No symbol) [0x00A520DB]\n\t(No symbol) [0x00A5C63B]\n\tBaseThreadInitThunk [0x753000F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77157BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77157B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m driver\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhttps://www.google.com/search?q=dog&hl=en-US&sxsrf=APwXEdd3Q08cBkL7ZvsiYS8Rrg3H3aYbKA\u001b[39m\u001b[39m%\u001b[39m\u001b[39m3A1679755091672&ei=UwcfZMbdKMLBjuMP5fqk6AE&ved=0ahUKEwiG07Gsp_f9AhXCoGMGHWU9CR0Q4dUDCA8&uact=5&oq=dog&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECCMQJzIECCMQJzIECCMQJzIQCC4QFBCHAhDUAhCxAxCABDINCAAQgAQQFBCHAhCxAzIICC4QsQMQgAQyCAguEIAEELEDMgsIABCABBCxAxCDATILCC4QgAQQsQMQ1AIyCAgAEIAEELEDOgcIABCKBRBDOgsIABCKBRCxAxCDAToFCAAQgAQ6EAguEIAEEBQQhwIQsQMQ1AJKBAhBGABQAFiyAWCzBWgAcAF4AIABvAGIAYQEkgEDMC4zmAEAoAEBwAEB&sclient=gws-wiz-serp\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Find the span element with the text \"What are dogs\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m search_box \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_element(\u001b[39m\"\u001b[39;49m\u001b[39mcss_selector\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mdiv#rhs div.kp-blk div.kp-header ~ div span\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# span_element = driver.find_element(\"xpath\",\"//span[contains(text(), 'What is the smartest dog?')]\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[39m# Get the coordinates of the span element\u001b[39;00m\n\u001b[0;32m     15\u001b[0m span_location \u001b[39m=\u001b[39m span_element\u001b[39m.\u001b[39mlocation_once_scrolled_into_view\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:830\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    827\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    828\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 830\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: invalid locator\n  (Session info: chrome=111.0.5563.111)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00AADCE3]\n\t(No symbol) [0x00A439D1]\n\t(No symbol) [0x00954DA8]\n\t(No symbol) [0x00980292]\n\t(No symbol) [0x009803AB]\n\t(No symbol) [0x009AEE62]\n\t(No symbol) [0x0099AF14]\n\t(No symbol) [0x009AD57C]\n\t(No symbol) [0x0099ACC6]\n\t(No symbol) [0x00976F68]\n\t(No symbol) [0x009780CD]\n\tGetHandleVerifier [0x00D23832+2506274]\n\tGetHandleVerifier [0x00D59794+2727300]\n\tGetHandleVerifier [0x00D5E36C+2746716]\n\tGetHandleVerifier [0x00B56690+617600]\n\t(No symbol) [0x00A4C712]\n\t(No symbol) [0x00A51FF8]\n\t(No symbol) [0x00A520DB]\n\t(No symbol) [0x00A5C63B]\n\tBaseThreadInitThunk [0x753000F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77157BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77157B8E+238]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pyautogui\n",
    "from selenium import webdriver\n",
    "\n",
    "# Set up Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.google.com/search?q=dog&hl=en-US&sxsrf=APwXEdd3Q08cBkL7ZvsiYS8Rrg3H3aYbKA%3A1679755091672&ei=UwcfZMbdKMLBjuMP5fqk6AE&ved=0ahUKEwiG07Gsp_f9AhXCoGMGHWU9CR0Q4dUDCA8&uact=5&oq=dog&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECCMQJzIECCMQJzIECCMQJzIQCC4QFBCHAhDUAhCxAxCABDINCAAQgAQQFBCHAhCxAzIICC4QsQMQgAQyCAguEIAEELEDMgsIABCABBCxAxCDATILCC4QgAQQsQMQ1AIyCAgAEIAEELEDOgcIABCKBRBDOgsIABCKBRCxAxCDAToFCAAQgAQ6EAguEIAEEBQQhwIQsQMQ1AJKBAhBGABQAFiyAWCzBWgAcAF4AIABvAGIAYQEkgEDMC4zmAEAoAEBwAEB&sclient=gws-wiz-serp\")\n",
    "\n",
    "# Find the span element with the text \"What are dogs\"\n",
    "search_box = driver.find_element(\"css_selector\",\"div#rhs div.kp-blk div.kp-header ~ div span\")\n",
    "\n",
    "# span_element = driver.find_element(\"xpath\",\"//span[contains(text(), 'What is the smartest dog?')]\")\n",
    "\n",
    "# Get the coordinates of the span element\n",
    "span_location = span_element.location_once_scrolled_into_view\n",
    "\n",
    "# Move the mouse to the coordinates of the span element\n",
    "pyautogui.moveTo(span_location['x'], span_location['y'])\n",
    "\n",
    "# Click on the span element\n",
    "pyautogui.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
