{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyautogui\n",
    "\n",
    "# # list of images related to the target image\n",
    "# image_list = ['images_button.png', 'img2.png', 'img3.png', 'img4.png']\n",
    "\n",
    "# # search for all the related images on the screen\n",
    "# matches = []\n",
    "# for image in image_list:\n",
    "#     match = pyautogui.locateAllOnScreen(image, grayscale=True, confidence=0.8)\n",
    "#     matches.extend(list(match))\n",
    "\n",
    "# # find the best match among all the locations\n",
    "# best_match = None\n",
    "# max_score = 0\n",
    "# for match in matches:\n",
    "#     score = match[2]  # confidence score\n",
    "#     if score > max_score:\n",
    "#         best_match = match\n",
    "#         max_score = score\n",
    "\n",
    "# # click on the center of the best match (if found)\n",
    "# if best_match is not None:\n",
    "#     x, y, _, _ = best_match\n",
    "#     center_x = x + (_ // 2)\n",
    "#     center_y = y + (_ // 2)\n",
    "#     pyautogui.click(center_x, center_y)\n",
    "    \n",
    "# else:\n",
    "#     print(\"Best match not found lol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyautogui\n",
    "\n",
    "# # list of images related to the target image\n",
    "# image_list = ['vid1.png', 'vid2.png', 'vid3.png', 'vid4.png','vid5.png','vid6.png']\n",
    "\n",
    "# # search for all the related images on the screen\n",
    "# matches = []\n",
    "# for image in image_list:\n",
    "#     match = pyautogui.locateAllOnScreen(image, grayscale=True, confidence=0.8)\n",
    "#     matches.extend(list(match))\n",
    "\n",
    "# # find the best match among all the locations\n",
    "# best_match = None\n",
    "# max_score = 0\n",
    "# for match in matches:\n",
    "#     score = match[2]  # confidence score\n",
    "#     if score > max_score:\n",
    "#         best_match = match\n",
    "#         max_score = score\n",
    "\n",
    "# # click on the center of the best match (if found)\n",
    "# if best_match is not None:\n",
    "#     x, y, _, _ = best_match\n",
    "#     center_x = x + (_ // 2)\n",
    "#     center_y = y + (_ // 2)\n",
    "#     pyautogui.click(center_x, center_y)\n",
    "    \n",
    "# else:\n",
    "#     print(\"Best match not found lol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'has_suggestion' could not be imported from 'C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\prompt_toolkit\\filters\\__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text():\n",
    "    import io\n",
    "    import wave\n",
    "    import pyaudio\n",
    "    import string\n",
    "    import whisper\n",
    "\n",
    "    # Set up audio recording parameters\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 5\n",
    "\n",
    "    # Create an instance of PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open a new stream for recording\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    # Create a buffer to store the recorded audio\n",
    "    frames = []\n",
    "\n",
    "    # Record the audio for the specified number of seconds\n",
    "    print(\"Recording started...\")\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio as a WAV file\n",
    "    with wave.open(\"recorded_audio.wav\", \"wb\") as wav_file:\n",
    "        wav_file.setnchannels(CHANNELS)\n",
    "        wav_file.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wav_file.setframerate(RATE)\n",
    "        wav_file.writeframes(b\"\".join(frames))\n",
    "\n",
    "    ##Model code has been already run above\n",
    "\n",
    "    result = model.transcribe('recorded_audio.wav')\n",
    "\n",
    "    cleaned_result = result['text'].lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "    return cleaned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'open images'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To be run whenever want to record\n",
    "ressssult = speech_to_text()\n",
    "ressssult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickGoogleButtons(image_list):\n",
    "    # search for all the related images on the screen\n",
    "    matches = []\n",
    "\n",
    "    for image in image_list:\n",
    "        match = pyautogui.locateAllOnScreen(image, grayscale=True, confidence=0.8)\n",
    "        matches.extend(list(match))\n",
    "\n",
    "        # find the best match among all the locations\n",
    "    best_match = None\n",
    "    max_score = 0\n",
    "    for match in matches:\n",
    "        score = match[2]  # confidence score\n",
    "        if score > max_score:\n",
    "            best_match = match\n",
    "            max_score = score\n",
    "\n",
    "    # click on the center of the best match (if found)\n",
    "    if best_match is not None:\n",
    "        x, y, _, _ = best_match\n",
    "        center_x = x + (_ // 2)\n",
    "        center_y = y + (_ // 2)\n",
    "        pyautogui.click(center_x, center_y)\n",
    "        \n",
    "    else:\n",
    "        print(\"Best match not found lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "query = ressssult\n",
    "\n",
    "if query=='open images':\n",
    "        # list of images related to the target image\n",
    "    image_list = ['images_button.png', 'img2.png', 'img3.png', 'img4.png']\n",
    "\n",
    "    #calling the function\n",
    "    clickGoogleButtons(image_list)\n",
    "\n",
    "\n",
    "elif query == \"open videos\":\n",
    "        # list of images related to the target image\n",
    "    image_list = ['vid1.png', 'vid2.png', 'vid3.png', 'vid4.png','vid5.png','vid6.png']\n",
    "    \n",
    "    #calling the function\n",
    "    clickGoogleButtons(image_list)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58dbfdb34cf82127b32c5737e6183911655ff227e5c11e8f5e4b25048ae98ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
